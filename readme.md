# Mini-VeVV-Demo

Ein vollstÃ¤ndiges Event-Driven-Microservice-Demo-Projekt zur Umsetzung elektronischer AntrÃ¤ge im Verwaltungsverfahren â€“ inspiriert von der VeVV-Verordnung (Kanton ZÃ¼rich).

## âœ… Ziel des Projekts
Diese Demo simuliert eine vollstÃ¤ndige digitale Verfahrensabwicklung mit:
- Angular-Frontend zur Antragstellung
- Spring Boot Backend mit Kafka zur Verarbeitung
- Kafka Consumers fÃ¼r Archivierung und Benachrichtigung
- PostgreSQL zur Persistenz
- Kafka UI zur Einsicht der Topics
- Docker Compose fÃ¼r lokale Entwicklungsumgebung

Das Projekt ist **lasttestfÃ¤hig, fehlertolerant** und demonstriert zentrale Konzepte wie **Retry-Mechanismen**, **Transaktionen**, **Fallbacks**, **State Management** und **resiliente Microservices**.

---

## ğŸš€ Skalierter Tech-Plan: VeVV Demo â€“ Advanced Edition (5 intensive Tage)
**Fokus auf Java/Kafka Backend-Exzellenz mit realistischer KomplexitÃ¤t**

### ğŸ§  Tag 1 â€“ Kafka-Architektur & Resilienz
- âœ”ï¸ Microservices: Antragseinreichung, Benachrichtigung, Archivierung
- âœ”ï¸ Kafka + Kafka UI mit Docker Compose
- âœ”ï¸ Erweiterung der Topic-Struktur:
  - `antraege`, `antraege-validiert`, `antraege-abgelehnt`
  - `archiv-fehler`, `dead-letter`
- Kafka Retry-Mechanismen:
  - Spring Retry (`@Retryable`, `@Recover`)
  - Manuelles Retry mit DLQ (Dead Letter Topic)
- Resilienter Consumer: Timeout, Retry, Logging
- Tests mit fehlerhaften JSON-Nachrichten

### ğŸ’¼ Tag 2 â€“ Transaktionen, Fehlerhandling, Validierung
- Spring `@Transactional` + DB-Kafka-Konsistenz
- Outbox-Pattern fÃ¼r Eventual Consistency
- Bean Validation (`@NotBlank`, `@Size`, etc.)
- Globales Fehlerhandling mit `@ControllerAdvice`
  - z.â€¯B. `MethodArgumentNotValidException`, `KafkaSendException`
- OpenAPI/Swagger mit Fehlerdokumentation (`400`, `409`, `500`)

### ğŸ‹ï¸ Tag 3 â€“ Lasttest & Kafka Simulation
- Client-Simulator (Java CLI):
  - Multi-Threaded `POST /antrag` mit Zufallsdaten (Faker-Lib)
  - Performance-Metriken: RPS, Fehlerquote
- Kafka Benchmarking: AntrÃ¤ge pro Minute
- Archiv-Service kÃ¼nstlich verlangsamen â†’ Backpressure sichtbar
- Logging + Alerting bei Fehlern (z.â€¯B. `archiv-fehler` Topic)

### ğŸ” Tag 4 â€“ Sicherheit & Zustellplattform
- Spring Security: geschÃ¼tzter Zugang zu `/api/antrag`
  - z.â€¯B. fester Bearbeiter-Token
- Dummy-Signatur-Service (PDF Sign Simulation)
- Upload-API vorbereiten (Struktur ohne echte Dateiannahme)
- API-Design: Trennung intern/extern (`/api/public`, `/api/internal`)

### ğŸ§¾ Tag 5 â€“ Skalierbarkeit, SAGA & PrÃ¤sentation
- SAGA Pattern (Archiv + Benachrichtigung mÃ¼ssen erfolgreich sein)
- Business-Logik: Antrag-Ablehnung (z.â€¯B. unvollstÃ¤ndig)
- Kafka Scaling: Partitionierung, Consumer Groups
- Crash Recovery mit manuellen Service-AusfÃ¤llen getestet
- Angular-Frontend:
  - Paging, Range-Filter, max. Page Size
  - ZÃ¤hlung & Warnung bei zu vielen Treffern
- Finalisierung: Architekturdiagramm + Screencast (optional)

---

## ğŸ§  UrsprÃ¼nglicher Tagesplan (Umgesetzt innerhalb von 4h)

### ğŸ—“ï¸ **Tag 1 â€“ Architektur-GrundgerÃ¼st & Kafka-Lifecycle**
- âœ”ï¸ Setup der Projektstruktur (3 Microservices + 1 Frontend)
- âœ”ï¸ Kafka, Zookeeper & PostgreSQL via Docker Compose
- âœ”ï¸ Spring Boot Producer + Consumer (Hello World mit Kafka)
- âœ”ï¸ Kafka UI fÃ¼r Topic Monitoring
- âœ”ï¸ Angular CLI Projekt + Grundstruktur

### ğŸ—“ï¸ **Tag 2 â€“ REST + Antrag-Erfassung mit Angular**
- âœ”ï¸ REST-Endpoint `POST /api/antrag` mit Spring Boot
- âœ”ï¸ Speichern des Antrags in PostgreSQL
- âœ”ï¸ Angular-Formular fÃ¼r Antragstellung
- âœ”ï¸ Kafka-Producer wird durch POST ausgelÃ¶st
- âœ”ï¸ End-to-End-Demo: Angular â†’ REST â†’ Kafka

### ğŸ—“ï¸ **Tag 3 â€“ Kafka Consumer, Verarbeitung & Archivierung**
- âœ”ï¸ Service 2: Kafka-Consumer â€Benachrichtigungâ€œ â†’ Log-Ausgabe
- âœ”ï¸ Service 3: Kafka-Consumer â€Archivierungâ€œ â†’ PDF-Dummy + Speicherung
- âœ”ï¸ EinfÃ¼hrung in Consumer Groups, Offsets, Partitionen
- âœ”ï¸ Fehlerbehandlung + Retry beim Kafka-Consumer
- âœ”ï¸ Crash Recovery: Consumer/Producer neustarten ohne Datenverlust

### ğŸ—“ï¸ **Tag 4 â€“ API Design, Doku & Sicherheit**
- âœ”ï¸ Erweiterte REST-Fehlerbehandlung mit Status-Codes & Validation
- âœ”ï¸ Swagger/OpenAPI Dokumentation
- âœ”ï¸ CORS fÃ¼r Angular freigeben
- âœ”ï¸ Simpler Healthcheck-Endpoint + Error Logging Middleware
- âœ”ï¸ Konfiguration Ã¼ber `application.yaml` ausgelagert (zukunftsfÃ¤hig)

### ğŸ—“ï¸ **Tag 5 â€“ Lasttest, Resilienz, PrÃ¤sentation**
- âœ”ï¸ Lasttest-Simulator: bis zu 500 parallele Clients
- âœ”ï¸ Simulierter Kafka-Ausfall + automatische Recovery
- âœ”ï¸ Retry-Strategien (Spring Retry + Kafka Consumer Backoff)
- âœ”ï¸ Paging + Range-Filter im Frontend (Angular)
- âœ”ï¸ Fehlerfeedback im UI bei zu groÃŸer Datenmenge (limit-basierte API)
- âœ”ï¸ Fallback-Mechanismus falls Archivierung/Benachrichtigung fehlschlÃ¤gt
- âœ”ï¸ `README.md` mit Screenshots & Architekturdiagramm

---

## ğŸš€ Starten
### Voraussetzungen:
- Docker Desktop (inkl. Docker Compose)
- Java 21 (fÃ¼r Spring Boot)
- Node.js + Angular CLI (fÃ¼r das Frontend)

### Backend starten
```bash
cd docker
docker-compose up -d
```

Starte anschlieÃŸend jeden Spring Boot Microservice einzeln:
```bash
cd antragsservice
./mvnw spring-boot:run

cd benachrichtigungsservice
./mvnw spring-boot:run

cd archivierungsservice
./mvnw spring-boot:run
```

### Frontend starten (Angular)
```bash
cd frontend
npm install
ng serve
```

Angular lÃ¤uft auf: [http://localhost:4200](http://localhost:4200)

Kafka UI: [http://localhost:8088](http://localhost:8088) (fÃ¼r Debugging)

---

## ğŸ§ª Testszenarien & Fehler-Simulation

- ğŸ” **Crash Recovery:** Stoppe `docker-kafka-1`, produziere AntrÃ¤ge weiter â†’ Consumer holen nach Reconnect alle Daten nach
- ğŸ§± **Archiv-Service stoppen:** â†’ Teste Fallback & Logs im Benachrichtigungsservice
- ğŸ“ˆ **Lasttest:** Bot-Script mit 500 Requests/s â†’ Kafka + DB Performance
- âŒ **Fehlermeldung bei kaputten POST-Daten** â†’ validierte DTOs + Status 400
- ğŸ“„ **Millionen-Dokumente-Test:** API liefert max. 500 EintrÃ¤ge je Page + Warnung bei >10k
- ğŸ”„ **Simulierter Service-Ausfall (z.â€¯B. Archiv)**: System fÃ¤ngt sich nach Neustart wieder automatisch

---

## ğŸ” Architekturprinzipien
- **Microservice Design** mit loser Kopplung via Kafka
- **Fehlertoleranz:** Retry + Dead Letter Topics mÃ¶glich
- **Skalierbarkeit:** Consumer parallelisiert via GroupId + Partition
- **Trennung von Concern:** UI, API, Verarbeitung, Archivierung getrennt
- **Transaktionssicherheit:** Outbox + Retry Logik

---

## âœ¨ Optional & Zukunft (nicht umgesetzt, aber vorgesehen)
- âœ‰ï¸ E-Mail-Benachrichtigung (SMTP / Kafka Consumer)
- ğŸ§¾ Integration mit ELO / DMS-Schnittstelle
- ğŸ” JWT-Login & SSO Ã¼ber ZÃ¼rikonto / Keycloak
- ğŸ“¦ Deployment mit GitHub Actions & Docker Registry
- ğŸ“Š Monitoring mit Prometheus & Grafana
- ğŸ§ª Testcontainers fÃ¼r CI/CD & Contract Testing

---

### wichtige commands:
docker exec -it docker-kafka-1 kafka-topics --create --topic antraege-validiert --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1



## ğŸ‘¨â€ğŸ’» Entwickelt von [@HeldDigital](https://github.com/HeldDigital)
FÃ¼r Schulungszwecke & zur Vorbereitung auf das VeVV-Projekt der Stadt ZÃ¼rich



Tag 2:

ğŸ’¡ Was passiert hier eigentlich?
Wir setzen das Outbox-Pattern um â€“ ein bewÃ¤hrtes Architekturprinzip zur eventuellen Konsistenz zwischen DB und Kafka.

ğŸ” Hintergrundproblem:
Stell dir vor:

Ein Benutzer sendet einen Antrag â†’ du speicherst ihn in der Datenbank (antragRepository.save(antrag)).

Danach willst du den Antrag gleichzeitig an Kafka senden (kafkaTemplate.send(...)).

Problem:
Was, wenn der Antrag gespeichert wird, aber dann der Kafka-Versand fehlschlÃ¤gt (Crash, Netzwerk, Fehler)?

â†’ Inkonistenz! Die Datenbank enthÃ¤lt den Antrag, aber die Event-Consumer wissen nichts davon.

âœ… LÃ¶sung: Outbox Pattern
Wir machenâ€™s besser:

Antrag speichern + Kafka-Nachricht als OutboxEvent speichern â†’ in 1 Transaktion.

SpÃ¤ter (asynchron) prÃ¼ft ein Scheduler alle OutboxEvent mit sent = false.

FÃ¼r jedes Event:

Wir senden es an Kafka

Wenn erfolgreich â†’ sent = true in der DB â†’ âœ… erledigt

Vorteil:
Keine Nachricht geht verloren

Kafka wird nur benachrichtigt, wenn auch die DB gespeichert wurde

Crash-sicher: Bei Neustart lÃ¤uft der Scheduler einfach weiter


Siehe : `docs/dev-notes-outbox.md` 

